{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b160825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "\n",
    "from timm.utils import accuracy, AverageMeter\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import build_model\n",
    "from models.swin_transformer import SwinTransformer\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.cuda.amp\n",
    "\n",
    "import torchvision \n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from timm.data import create_transform\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86465d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "lr = 0.0001\n",
    "weight_decay = 0.000001\n",
    "t_total = 10000\n",
    "eval_every = 20\n",
    "\n",
    "pt_path = \"./img\"\n",
    "tr_path = \"./img\"\n",
    "ts_path = \"./img\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "874ed13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transform():\n",
    "\n",
    "    if True:\n",
    "        # this should always dispatch to transforms_imagenet_train\n",
    "        transform = create_transform(\n",
    "            input_size=224,\n",
    "            is_training=True,\n",
    "            color_jitter=0.4,\n",
    "            auto_augment='rand-m9-mstd0.5-inc1',\n",
    "            interpolation=InterpolationMode.BICUBIC,\n",
    "            re_prob=0.25,\n",
    "            re_mode='pixel',\n",
    "            re_count=1\n",
    "        )\n",
    "\n",
    "        \n",
    "        return transform\n",
    "    \n",
    "def get_loader(pt_path, tr_path, ts_path, pt_batch, tr_batch, ts_batch):\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomResizedCrop((224, 224), scale=(0.05, 1.0)), # center crop으로 변경 필요\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "    pretrain_transform = build_transform()\n",
    "    \n",
    "    pretrain_dataset = torchvision.datasets.ImageFolder(pt_path,transform = pretrain_transform)\n",
    "    train_dataset = torchvision.datasets.ImageFolder(tr_path,transform = transform_train)\n",
    "    test_dataset = torchvision.datasets.ImageFolder(ts_path,transform = transform_test)\n",
    "\n",
    "    pretrain_train_loader = DataLoader(pretrain_dataset,\n",
    "                              batch_size=pt_batch,\n",
    "                              num_workers=8,\n",
    "                              pin_memory=True,\n",
    "                            shuffle=True\n",
    "                             )\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=tr_batch,\n",
    "                              num_workers=8,\n",
    "                              pin_memory=True,\n",
    "                              shuffle=True\n",
    "                             )\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                              batch_size=ts_batch,\n",
    "                              num_workers=8,\n",
    "                              pin_memory=True\n",
    "                             )\n",
    "    return pretrain_train_loader, train_loader, test_loader\n",
    "\n",
    "def build_model():\n",
    "    \n",
    "    model = SwinTransformer(img_size=224,\n",
    "                            patch_size=2,\n",
    "                            in_chans=3,\n",
    "                            num_classes=1,\n",
    "                            embed_dim=96,\n",
    "                            depths=[2, 2, 6, 2],\n",
    "                            num_heads=[3, 6, 12, 24],\n",
    "                            window_size=7,\n",
    "                            mlp_ratio=4,\n",
    "                            qkv_bias=True,\n",
    "                            qk_scale=None,\n",
    "                            drop_rate=0.0,\n",
    "                            drop_path_rate=0.1,\n",
    "                            ape=False,\n",
    "                            patch_norm=True,\n",
    "                            use_checkpoint=False)\n",
    "        #raise NotImplementedError(f\"Unkown model: {model_type}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e270ac1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lazyy\\anaconda3\\lib\\site-packages\\torch\\functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.load_state_dict(torch.load('pretrained_swin_wo_head.npz',map_location=torch.device('cpu')),strict=False)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(),  eps=1e-08, betas=(0.9, 0.999), lr=lr, weight_decay=0.00001)\n",
    "_, train_loader, test_loader = get_loader(pt_path = pt_path, tr_path = tr_path, ts_path = ts_path, pt_batch = batch_size, tr_batch = batch_size, ts_batch = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c93bbf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "def valid(model, test_loader):\n",
    "    # Validation!\n",
    "    eval_losses = AverageMeter()\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    all_preds, all_label = [], []\n",
    "    epoch_iterator = tqdm(test_loader,\n",
    "                          desc=\"Validating... (loss=X.X)\",\n",
    "                          bar_format=\"{l_bar}{r_bar}\",\n",
    "                          dynamic_ncols=True,)\n",
    "    loss_fct = F.binary_cross_entropy_with_logits\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(test_loader):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            x, y = batch\n",
    "            y = y.view(-1)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(x).squeeze(1)\n",
    "                eval_loss = loss_fct(logit,y.type(torch.FloatTensor))\n",
    "                eval_losses.update(eval_loss.item())\n",
    "\n",
    "                preds = torch.argmax(logits, dim=-1)\n",
    "                #print(preds.shape)\n",
    "\n",
    "            if len(all_preds) == 0:\n",
    "                all_preds.append(preds.detach().cpu().numpy())\n",
    "                all_label.append(y.detach().cpu().numpy())\n",
    "            else:\n",
    "                all_preds[0] = np.append(\n",
    "                    all_preds[0], preds.detach().cpu().numpy(), axis=0\n",
    "                )\n",
    "                all_label[0] = np.append(\n",
    "                    all_label[0], y.detach().cpu().numpy(), axis=0\n",
    "                )\n",
    "        #epoch_iterator.set_description(\"Validating... (loss=%2.5f)\" % eval_losses.val)\n",
    "\n",
    "\n",
    "    all_preds, all_label = all_preds[0], all_label[0]\n",
    "\n",
    "    accuracy = simple_accuracy(all_preds, all_label)\n",
    "\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"Valid Loss: %2.5f\" % eval_losses.avg)\n",
    "    print(\"Valid Accuracy: %2.5f\" % (accuracy*100))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5d178cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lazyy\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "Training (X / X Steps) (loss=X.X):   0%|| 0/5 [00:00<?, ?it/s]C:\\Users\\lazyy\\anaconda3\\lib\\site-packages\\torch\\autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "Training (1 / 10000 Steps) (loss=0.83463):  20%|| 1/5 [00:12<00:50, 12.68s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1496/239643571.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fct = F.binary_cross_entropy_with_logits\n",
    "losses = AverageMeter()\n",
    "global_step = 0\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "while True:\n",
    "    model.train()\n",
    "    epoch_iterator = tqdm(train_loader,\n",
    "                          desc=\"Training (X / X Steps) (loss=X.X)\",\n",
    "                          bar_format=\"{l_bar}{r_bar}\",\n",
    "                          dynamic_ncols=True\n",
    "                         )\n",
    "    \n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        optimizer.zero_grad()\n",
    "        x, y = batch\n",
    "        y = y.view(-1)\n",
    "\n",
    "        \n",
    "    \n",
    "        with torch.cuda.amp.autocast():\n",
    "            logit = model(x).squeeze(1)\n",
    "            loss = loss_fct(logit,y.type(torch.FloatTensor))\n",
    "        losses.update(loss.item())\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "            \n",
    "\n",
    "        global_step += 1\n",
    "        epoch_iterator.set_description(\n",
    "                    \"Training (%d / %d Steps) (loss=%2.5f)\" % (global_step, t_total, losses.val)\n",
    "                )\n",
    "        \n",
    "        if global_step % eval_every == 0:\n",
    "            torch.save(model.state_dict(),'fine_tuned_swin.npz')\n",
    "            #acc = valid(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a136c5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "700f0ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_param(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_param(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
